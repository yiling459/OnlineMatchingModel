{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy Reward: 61\n",
      "OPT Reward: 54\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class OnlineMatchingModel:\n",
    "    def __init__(self, N, T, E, rewards, usage_duration_distributions):\n",
    "        # Initialize the model parameters\n",
    "        self.N = N  # Number of offline vertices (resources)\n",
    "        self.T = T  # Number of online vertices (requests)\n",
    "        self.E = E  # Edges in the bipartite graph\n",
    "        self.rewards = rewards  # Reward for each resource\n",
    "        self.usage_duration_distributions = usage_duration_distributions  # Usage duration distributions\n",
    "\n",
    "    def greedy_algorithm(self):\n",
    "        total_reward = 0\n",
    "        resource_availability = [0] * self.N  # Track when resources become available\n",
    "        for t in range(self.T):\n",
    "            available_resources = [i for i in range(self.N) if t >= resource_availability[i]]\n",
    "            # Find the highest reward resource that can be matched\n",
    "            best_resource = None\n",
    "            best_reward = 0\n",
    "            for i in available_resources:\n",
    "                if (i, t) in self.E and self.rewards[i] > best_reward:\n",
    "                    best_reward = self.rewards[i]\n",
    "                    best_resource = i\n",
    "            if best_resource is not None:\n",
    "                total_reward += best_reward\n",
    "                # Sample the usage duration\n",
    "                duration = np.random.choice(self.usage_duration_distributions[best_resource])\n",
    "                resource_availability[best_resource] = t + duration\n",
    "        return total_reward\n",
    "\n",
    "    def clairvoyant_opt(self, arrival_sequence):\n",
    "        total_reward = 0\n",
    "        resource_availability = [0] * self.N\n",
    "        for t in range(self.T):\n",
    "            current_request = arrival_sequence[t]\n",
    "            # Check all resources that can be matched with the current request\n",
    "            for i in range(self.N):\n",
    "                if (i, current_request) in self.E and resource_availability[i] <= t:\n",
    "                    total_reward += self.rewards[i]\n",
    "                    duration = np.random.choice(self.usage_duration_distributions[i])\n",
    "                    resource_availability[i] = t + duration\n",
    "                    break  # Assuming one match per request\n",
    "        return total_reward\n",
    "\n",
    "\n",
    "# Example usage\n",
    "N = 5  # Number of resources\n",
    "T = 10  # Number of requests\n",
    "E = [(i, j) for i in range(N) for j in range(T) if random.random() > 0.5]  # Randomly generate edges\n",
    "rewards = np.random.randint(1, 10, N)\n",
    "usage_duration_distributions = [np.random.randint(1, 5, 10) for _ in range(N)]\n",
    "\n",
    "model = OnlineMatchingModel(N, T, E, rewards, usage_duration_distributions)\n",
    "greedy_reward = model.greedy_algorithm()\n",
    "arrival_sequence = np.random.permutation(T)  # Random arrival sequence for OPT\n",
    "opt_reward = model.clairvoyant_opt(arrival_sequence)\n",
    "\n",
    "print(f\"Greedy Reward: {greedy_reward}\")\n",
    "print(f\"OPT Reward: {opt_reward}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main differences between Inventory Balancing Algorithm and Rank Based Allocation Algorithm:\n",
    "* Goals:\n",
    "    * IBA: Balance the cost of holding inventory with the risk of being out of stock, optimizing inventory levels by adjusting replenishment points and order volumes.\n",
    "    * RBA: Maximize long-term rewards or utility while considering the reuse of resources. By prioritizing the highest-ranking available units, the algorithm attempts to optimize allocation decisions while keeping resources efficiently recycled.\n",
    "* Scenario:\n",
    "    * IBA: Inventory management and demand matching\n",
    "    * RBA: Address the reusability of resources and dynamically reprioritize resource units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Greedy Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward obtained: 120\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class OnlineMatchingModel:\n",
    "    def __init__(self, N, T, E, rewards, usage_duration_distributions):\n",
    "        self.N = N\n",
    "        self.T = T\n",
    "        self.E = set(E)  # Ensure E is a set for faster lookup\n",
    "        self.rewards = rewards\n",
    "        self.usage_duration_distributions = usage_duration_distributions\n",
    "\n",
    "    def greedy_algorithm(self):\n",
    "        total_reward = 0\n",
    "        resource_availability = [0] * self.N\n",
    "        for t in range(self.T):\n",
    "            available_resources = [i for i in range(self.N) if t >= resource_availability[i]]\n",
    "            best_resource = None\n",
    "            best_reward = 0\n",
    "            for i in available_resources:\n",
    "                if (i, t) in self.E and self.rewards[i] > best_reward:\n",
    "                    best_reward = self.rewards[i]\n",
    "                    best_resource = i\n",
    "            if best_resource is not None:\n",
    "                total_reward += best_reward\n",
    "                duration = np.random.choice(self.usage_duration_distributions[best_resource])\n",
    "                resource_availability[best_resource] = t + duration\n",
    "        return total_reward\n",
    "# Example parameters\n",
    "N = 3\n",
    "T = 10\n",
    "E = [(0, 1), (0, 2), (1, 3), (1, 4), (2, 5), (2, 6), (0, 7), (1, 8), (2, 9)]\n",
    "rewards = [10, 15, 20]  # Reward for matching each resource\n",
    "usage_duration_distributions = [\n",
    "    [1, 2, 3],  # Resource 0 can be busy for 1, 2, or 3 periods\n",
    "    [2, 3],     # Resource 1 can be busy for 2 or 3 periods\n",
    "    [1, 4]      # Resource 2 can be busy for 1 or 4 periods\n",
    "]\n",
    "\n",
    "# Create an instance of the model and run the greedy algorithm\n",
    "model = OnlineMatchingModel(N, T, E, rewards, usage_duration_distributions)\n",
    "print(\"Total reward obtained:\", model.greedy_algorithm())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inventory Balancing Algorithm (with unreusable resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2189672  0.56749709 0.03701525 0.15807598 0.2789692 ]\n",
      "[1, 4, 0, 3, 2, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "class OnlineMatchingModel:\n",
    "    def __init__(self, N, T, E, rewards):\n",
    "        self.N = N  # Number of offline vertices (resources)\n",
    "        self.T = T  # Number of online vertices (requests)\n",
    "        self.E = E  # Edges in the bipartite graph\n",
    "        self.rewards = rewards  # Reward for each resource\n",
    "        \n",
    "        self.inventory = {}\n",
    "        for n in range(N):\n",
    "            self.inventory[n] = 1 # Each resource is initially set to available\n",
    "\n",
    "        \n",
    "    def g(self, x):\n",
    "        return np.exp(-x)\n",
    "    # Used to adjust the selected weight or priority of each resource\n",
    "    # When the ratio of the resource's remaining inventory x is high, the value of e^(-x) is smaller, \n",
    "    # which means that the priority of resources being selected is correspondingly higher, \n",
    "    # because we are more inclined to use resources with more remaining inventory\n",
    "    \n",
    "    def allocate_resource(self, t):\n",
    "        scores = {}\n",
    "        for n in self.E[t]:\n",
    "            if self.inventory[n] > 0:  # Allocation is considered only when resources are available\n",
    "                score = (1 - self.g(self.inventory[n])) * self.rewards[n]\n",
    "                scores[n] = score\n",
    "\n",
    "        if scores:\n",
    "            selected_resource = max(scores, key=scores.get)\n",
    "            self.inventory[selected_resource] = 0  # After allocation, the resource is marked as unavailable\n",
    "            return selected_resource\n",
    "        return None  # If no resources are available, return None\n",
    "    \n",
    "# sample\n",
    "N = 5\n",
    "T = 10\n",
    "E = {}\n",
    "for t in range(T):\n",
    "    E[t] = range(N)\n",
    "\n",
    "rewards = np.random.rand(N)\n",
    "print(rewards)\n",
    "model = OnlineMatchingModel(N, T, E, rewards)\n",
    "\n",
    "allocations = []\n",
    "for t in range(T):\n",
    "    allocation = model.allocate_resource(t)\n",
    "    allocations.append(allocation)\n",
    "\n",
    "print(allocations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inventory Balancing Algorithm (reusable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3, 3, 4, 4, 3, 4, 4, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class OnlineMatchingModel:\n",
    "    def __init__(self, N, T, E, rewards, usage_duration_distributions):\n",
    "        self.N = N  # Number of offline vertices (resources)\n",
    "        self.T = T  # Number of online vertices (requests)\n",
    "        self.E = E  # Edges in the bipartite graph\n",
    "        self.rewards = rewards  # Reward for each resource\n",
    "        self.usage_duration_distributions = usage_duration_distributions  # Usage duration distributions\n",
    "\n",
    "        self.inventory = {}\n",
    "        for n in range(N):\n",
    "            self.inventory[n] = 1  # Each resource is initially set to available\n",
    "        \n",
    "        self.return_times = {}\n",
    "        for n in range(N):\n",
    "            self.return_times[n] = []  # Initializes the return time list for each resource\n",
    "    \n",
    "    def g(self, x):\n",
    "        return np.exp(-x)\n",
    "    # Used to adjust the selected weight or priority of each resource\n",
    "    # When the ratio of the resource's remaining inventory x is high, the value of e^(-x) is smaller, \n",
    "    # which means that the priority of resources being selected is correspondingly higher, \n",
    "    # because we are more inclined to use resources with more remaining inventory\n",
    "\n",
    "    \n",
    "    def update_inventory(self, current_time):\n",
    "        for n in range(self.N):\n",
    "            updated_return_times = []\n",
    "            for return_time in self.return_times[n]:\n",
    "                if return_time > current_time:\n",
    "                    updated_return_times.append(return_time)\n",
    "            self.return_times[n] = updated_return_times\n",
    "            \n",
    "            if not updated_return_times:  # If there is no resource waiting to be returned, it is set to available\n",
    "                self.inventory[n] = 1\n",
    "            else:\n",
    "                self.inventory[n] = 0\n",
    "    \n",
    "    def allocate_resource(self, t):\n",
    "        self.update_inventory(t)\n",
    "        \n",
    "        scores = {}\n",
    "        for n in self.E[t]:\n",
    "            score = (1 - self.g(self.inventory[n])) * self.rewards[n]\n",
    "            scores[n] = score\n",
    "        \n",
    "        selected_resource = max(scores, key=scores.get)\n",
    "        \n",
    "        duration = np.random.choice(self.usage_duration_distributions[selected_resource])\n",
    "        self.return_times[selected_resource].append(t + duration)\n",
    "        \n",
    "        self.inventory[selected_resource] = 0\n",
    "        \n",
    "        return selected_resource\n",
    "\n",
    "# sample\n",
    "N = 5\n",
    "T = 10\n",
    "E = {}\n",
    "for t in range(T):\n",
    "    E[t] = range(N)\n",
    "\n",
    "rewards = np.random.rand(N)\n",
    "\n",
    "usage_duration_distributions = {}\n",
    "for n in range(N):\n",
    "    usage_duration_distributions[n] = [1, 2, 3]\n",
    "\n",
    "model = OnlineMatchingModel(N, T, E, rewards, usage_duration_distributions)\n",
    "\n",
    "allocations = []\n",
    "for t in range(T):\n",
    "    allocation = model.allocate_resource(t)\n",
    "    allocations.append(allocation)\n",
    "\n",
    "print(allocations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank Based Allocation Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage Duration Distributions: {0: [5, 4], 1: [4, 5], 2: [3, 4], 3: [5, 3]}\n",
      "At time 0, resource 1 unit 1 is allocated\n",
      "At time 1, resource 3 unit 1 is allocated\n",
      "At time 2, resource 2 unit 1 is allocated\n",
      "At time 3, resource 0 unit 1 is allocated\n",
      "At time 4, resource 0 unit 0 is allocated\n",
      "At time 5, resource 1 unit 1 is allocated\n",
      "At time 6, resource 3 unit 1 is allocated\n",
      "At time 7, resource 2 unit 1 is allocated\n",
      "At time 8, resource 0 unit 1 is allocated\n",
      "At time 9, resource 1 unit 1 is allocated\n",
      "At time 10, resource 3 unit 1 is allocated\n",
      "At time 11, resource 2 unit 1 is allocated\n",
      "At time 12, resource 0 unit 0 is allocated\n",
      "At time 13, resource 1 unit 1 is allocated\n",
      "At time 14, resource 3 unit 1 is allocated\n",
      "At time 15, resource 2 unit 1 is allocated\n",
      "At time 16, resource 0 unit 1 is allocated\n",
      "At time 17, resource 3 unit 1 is allocated\n",
      "At time 18, resource 1 unit 1 is allocated\n",
      "At time 19, resource 2 unit 1 is allocated\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class OnlineMatchingModel:\n",
    "    def __init__(self, N, T, E, rewards, usage_duration_distributions):\n",
    "        self.N = N  # Number of resources\n",
    "        self.T = T  # Number of time steps or requests\n",
    "        self.E = E  # Edges representing possible matches between resources and requests\n",
    "        self.rewards = rewards  # Rewards for allocating each resource\n",
    "        self.usage_duration_distributions = usage_duration_distributions  # Usage durations for each resource\n",
    "        \n",
    "        # Initialize resource units' availability, rank, and return time\n",
    "        # self.unit_availability = {n: [True for _ in range(len(usage_duration_distributions[n]))] for n in range(N)}\n",
    "        # self.unit_rank = {n: list(range(len(usage_duration_distributions[n]))) for n in range(N)}\n",
    "        # self.unit_return_time = {n: [-1 for _ in range(len(usage_duration_distributions[n]))] for n in range(N)}\n",
    "        \n",
    "        # Initialize resource units' availability\n",
    "        # For each resource, create a list indicating whether each unit is available\n",
    "        self.unit_availability = {}\n",
    "        for n in range(self.N):  # Iterate over each resource\n",
    "            availability_list = []  # Initialize an empty list for storing availability status of each unit\n",
    "            for _ in range(len(self.usage_duration_distributions[n])):  # Iterate over the number of units for each resource\n",
    "                availability_list.append(True)  # Initially every unit is available\n",
    "            self.unit_availability[n] = availability_list  # Assign the list to the corresponding resource in the dictionary\n",
    "        \n",
    "        # Initialize resource units' rank\n",
    "        # For each resource, create a list indicating the rank of each unit\n",
    "        self.unit_rank = {}\n",
    "        for n in range(self.N):  # Iterate over each resource\n",
    "            rank_list = []  # Initialize an empty list for storing rank of each unit\n",
    "            for rank in range(len(self.usage_duration_distributions[n])):  # Iterate over the number of units for each resource\n",
    "                rank_list.append(rank)  # Assign a rank to each unit\n",
    "            self.unit_rank[n] = rank_list  # Assign the list to the corresponding resource in the dictionary\n",
    "        \n",
    "        # Initialize resource units' return time\n",
    "        # For each resource, create a list indicating the return time of each unit\n",
    "        self.unit_return_time = {}\n",
    "        for n in range(self.N):  # Iterate over each resource\n",
    "            return_time_list = []  # Initialize an empty list for storing return time of each unit\n",
    "            for _ in range(len(self.usage_duration_distributions[n])):  # Iterate over the number of units for each resource\n",
    "                return_time_list.append(-1)  # Initially, there is no return time (-1 indicates not in use)\n",
    "            self.unit_return_time[n] = return_time_list  # Assign the list to the corresponding resource in the dictionary\n",
    "\n",
    "\n",
    "    def g(self, x):\n",
    "        return np.exp(-x)\n",
    "    \n",
    "    def update_availability(self, t):\n",
    "        # Iterate over each resource to update its units' availability\n",
    "        for i in range(self.N):\n",
    "            # Iterate over each unit of the resource\n",
    "            for k in range(len(self.unit_availability[i])):\n",
    "                # Check if the current time is greater than or equal to the return time of the unit\n",
    "                if t >= self.unit_return_time[i][k]:\n",
    "                    # If so, make the unit available again\n",
    "                    self.unit_availability[i][k] = True\n",
    "\n",
    "    def allocate_resource(self, t):\n",
    "        # First, update the availability of all resources at time t\n",
    "        self.update_availability(t)\n",
    "        \n",
    "        # Initialize a dictionary to store the scores for each available resource\n",
    "        scores = {}\n",
    "        # Iterate over the resources that are available at time t\n",
    "        for i in self.E[t]:\n",
    "            # Find all available units of resource i\n",
    "            available_units = [k for k, available in enumerate(self.unit_availability[i]) if available]\n",
    "            # If there are available units, calculate the score for the resource\n",
    "            if available_units:\n",
    "                # Find the highest ranked available unit of resource i\n",
    "                highest_ranked_unit = max(available_units, key=lambda x: self.unit_rank[i][x])\n",
    "                # Calculate the score based on the reward and the rank of the unit\n",
    "                scores[i] = self.rewards[i] * (1 - self.g(self.unit_rank[i][highest_ranked_unit] / len(self.unit_rank[i])))\n",
    "\n",
    "        # If there are any scores calculated, proceed to allocate a resource\n",
    "        if scores:\n",
    "            # Select the resource with the highest score\n",
    "            selected_resource = max(scores, key=scores.get)\n",
    "            # Find the highest ranked available unit of the selected resource\n",
    "            selected_unit = max([k for k, available in enumerate(self.unit_availability[selected_resource]) if available], \n",
    "                                key=lambda x: self.unit_rank[selected_resource][x])\n",
    "            # Mark the selected unit as unavailable\n",
    "            self.unit_availability[selected_resource][selected_unit] = False\n",
    "            # Set the return time for the unit based on the selected usage duration\n",
    "            duration = np.random.choice(self.usage_duration_distributions[selected_resource])\n",
    "            self.unit_return_time[selected_resource][selected_unit] = t + duration\n",
    "            # Return the selected resource and unit\n",
    "            return selected_resource, selected_unit\n",
    "        else:\n",
    "            # If no resources are available, return None\n",
    "            return None, None\n",
    "\n",
    "\n",
    "# Example usage\n",
    "N = 4  # Number of resources\n",
    "T = 20  # Number of time steps or requests\n",
    "E = {t: range(N) for t in range(T)}  # Possible matches between resources and requests  ### random edges\n",
    "rewards = np.random.rand(N)  # Random rewards for each resource\n",
    "\n",
    "# Generate usage duration distributions randomly\n",
    "usage_duration_distributions = {}\n",
    "for n in range(N):\n",
    "    usage_duration_distributions[n] = np.random.choice(range(3, 6), size=2, replace=False).tolist()\n",
    "\n",
    "print(\"Usage Duration Distributions:\", usage_duration_distributions)\n",
    "\n",
    "model = OnlineMatchingModel(N, T, E, rewards, usage_duration_distributions)\n",
    "\n",
    "for t in range(T):\n",
    "    resource, unit = model.allocate_resource(t)\n",
    "    if resource is not None:\n",
    "        print(f\"At time {t}, resource {resource} unit {unit} is allocated\")\n",
    "    else:\n",
    "        print(f\"At time {t}, no resource is allocated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic Assortment Optimization for Reusable Products with Random Usage Durations\n",
    "\n",
    "It is assumed that the expected revenue of each product depends not only on its own attributes but also on time. To simplify, we assume that the expected return on each product decreases linearly over time, meaning that each product may become less attractive over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the Online Matching Model...\n",
      "\n",
      "Time Step 0: X---\n",
      "Time Step 1: X--X\n",
      "Time Step 2: X-XX\n",
      "Time Step 3: ---X\n",
      "Time Step 4: --XX\n",
      "Time Step 5: -X--\n",
      "Time Step 6: XX--\n",
      "Time Step 7: XXX-\n",
      "Time Step 8: XXX-\n",
      "Time Step 9: -XX-\n",
      "Time Step 10: -XX-\n",
      "Time Step 11: -X--\n",
      "Time Step 12: XX--\n",
      "Time Step 13: XXX-\n",
      "Time Step 14: XX-X\n",
      "Time Step 15: X--X\n",
      "Time Step 16: X-X-\n",
      "Time Step 17: --X-\n",
      "Time Step 18: -XX-\n",
      "Time Step 19: -XX-\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class OnlineMatchingModel:\n",
    "    def __init__(self, N, T, rewards, usage_duration_distributions):\n",
    "        self.N = N  # Number of resources\n",
    "        self.T = T  # Number of time steps or requests\n",
    "        self.rewards = rewards  # Matrix of rewards\n",
    "        self.usage_duration_distributions = usage_duration_distributions  # Distribution of usage durations\n",
    "        self.state = np.zeros((N, T))  # State of each resource over time\n",
    "        self.linear_approximations = np.zeros((N, T))  # Linear approximation values\n",
    "\n",
    "    def compute_linear_approximations(self):\n",
    "        for t in range(self.T):\n",
    "            for n in range(self.N):\n",
    "                previous_resource_state = self.state[(n - 1) % self.N, t]\n",
    "                if previous_resource_state == 1:\n",
    "                    dependency_factor = 0.9\n",
    "                else:\n",
    "                    dependency_factor = 1.1\n",
    "                \n",
    "                adjusted_reward = self.rewards[n, t] * dependency_factor\n",
    "                time_decay = t * 0.1\n",
    "                self.linear_approximations[n, t] = adjusted_reward - time_decay\n",
    "\n",
    "    def transition_function(self, allocations, t):\n",
    "        for n in allocations:\n",
    "            duration = np.random.choice(self.usage_duration_distributions[n], 1)[0]\n",
    "            end_time = min(t + duration, self.T)\n",
    "            self.state[n, t:end_time] = 1\n",
    "\n",
    "    def greedy_policy(self, t):\n",
    "        available_resources = []\n",
    "        for n in range(self.N):\n",
    "            if self.state[n, t] == 0:\n",
    "                available_resources.append(n)\n",
    "\n",
    "        if not available_resources:\n",
    "            return []\n",
    "\n",
    "        # Find the resource with the maximum linear approximation value\n",
    "        max_value = float('-inf')\n",
    "        max_resource = None\n",
    "        for resource in available_resources:\n",
    "            if self.linear_approximations[resource, t] > max_value:\n",
    "                max_value = self.linear_approximations[resource, t]\n",
    "                max_resource = resource\n",
    "\n",
    "        return [max_resource] if max_resource is not None else []\n",
    "\n",
    "    def run(self):\n",
    "        self.compute_linear_approximations()\n",
    "        print(\"Running the Online Matching Model...\\n\")\n",
    "        for t in range(self.T):\n",
    "            allocations = self.greedy_policy(t)\n",
    "            self.transition_function(allocations, t)\n",
    "\n",
    "            # Generate the resource state string\n",
    "            resource_states = ''\n",
    "            for n in range(self.N):\n",
    "                resource_states += 'X' if self.state[n, t] else '-'\n",
    "            print(f\"Time Step {t}: {resource_states}\")\n",
    "\n",
    "# Example usage\n",
    "N = 4  # Number of resources\n",
    "T = 20  # Number of time steps\n",
    "rewards = np.random.rand(N, T)  # Random rewards\n",
    "usage_duration_distributions = [[1, 2, 3], [2, 3, 4], [1, 2], [2]]  # Modified usage durations\n",
    "\n",
    "model = OnlineMatchingModel(N, T, rewards, usage_duration_distributions)\n",
    "model.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inventory level 1: Expected Max Revenue = $8286.47\n",
      "Expected matched items matrix:\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 4.07661061e-13 5.40034064e-11\n",
      "  1.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.07653126e-13 5.40033982e-11\n",
      "  1.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.07660180e-13 5.40034048e-11\n",
      "  1.00000000e+00]]\n",
      "Inventory level 5: Expected Max Revenue = $8915.80\n",
      "Expected matched items matrix:\n",
      "[[5.06577684e-12 3.24784164e-01 6.75215836e-01 5.01899587e-11\n",
      "  0.00000000e+00]\n",
      " [5.39160265e-12 3.14165094e-09 9.99999997e-01 6.09072884e-11\n",
      "  0.00000000e+00]\n",
      " [5.46431821e-12 1.37843353e-09 9.99999999e-01 1.29768997e-10\n",
      "  0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 5.24281134e-12 1.68080129e-10\n",
      "  1.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 5.24280425e-12 1.68080121e-10\n",
      "  1.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 5.24279711e-12 1.68080114e-10\n",
      "  1.00000000e+00]]\n",
      "Inventory level 20: Expected Max Revenue = $9000.00\n",
      "Expected matched items matrix:\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 2.02979397e-10\n",
      "  1.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 2.01466257e-10\n",
      "  1.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.98482863e-10\n",
      "  1.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 2.13562227e-10\n",
      "  1.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 2.13562229e-10\n",
      "  1.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 2.13562233e-10\n",
      "  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "n = 5  # Number of products\n",
    "T = 300  # Number of periods\n",
    "prices = np.linspace(15, 30, n)  # Prices of products\n",
    "inventory_levels = [1, 5, 20]  # Inventory levels\n",
    "probabilities = np.array([1 / (20 - i) for i in range(1, 6)])  # Geometric distribution parameters\n",
    "\n",
    "# Prepare survival probabilities for the geometric distribution (product availability over time)\n",
    "survival_probabilities = np.array([(1 - probabilities[i]) ** np.arange(T) for i in range(n)])\n",
    "\n",
    "# Each inventory level simulation\n",
    "for inventory_level in inventory_levels:\n",
    "    # Decision variable: X[t, i] is now continuous between 0 and 1\n",
    "    X = cp.Variable((T, n), nonneg=True)\n",
    "\n",
    "    # Objective function: Maximize expected total revenue\n",
    "    revenue = cp.sum(cp.multiply(X, prices.reshape(1, n)))\n",
    "\n",
    "    # Constraints\n",
    "    constraints = []\n",
    "\n",
    "    # Constraint 1: The sum of probabilities for matching items in each time period cannot exceed 1\n",
    "    constraints += [cp.sum(X, axis=1) <= 1]\n",
    "\n",
    "    # Constraint 2: Cumulative expected matching for each item should not exceed its maximum capacity\n",
    "    for i in range(n):\n",
    "        constraints += [cp.sum(cp.multiply(X[:, i], survival_probabilities[i])) <= inventory_level]\n",
    "\n",
    "    # Constraint 3: X[t, i] must be between 0 and 1\n",
    "    constraints += [X <= 1]\n",
    "\n",
    "    # Constraint 4: Matching only if there is an edge - assuming all items are always available for simplicity\n",
    "    # If there are specific conditions where an item is not available, l_ti should be defined accordingly\n",
    "    l_ti = np.ones((T, n))  \n",
    "    constraints += [X <= l_ti]\n",
    "\n",
    "    # Define the optimization problem\n",
    "    prob = cp.Problem(cp.Maximize(revenue), constraints)\n",
    "\n",
    "    # Solve the problem\n",
    "    prob.solve()\n",
    "\n",
    "    # Output results\n",
    "    print(f\"Inventory level {inventory_level}: Expected Max Revenue = ${prob.value:.2f}\")\n",
    "    print(\"Expected matched items matrix:\")\n",
    "    print(X.value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
