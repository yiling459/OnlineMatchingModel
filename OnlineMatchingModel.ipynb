{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy Reward: 61\n",
      "OPT Reward: 54\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class OnlineMatchingModel:\n",
    "    def __init__(self, N, T, E, rewards, usage_duration_distributions):\n",
    "        # Initialize the model parameters\n",
    "        self.N = N  # Number of offline vertices (resources)\n",
    "        self.T = T  # Number of online vertices (requests)\n",
    "        self.E = E  # Edges in the bipartite graph\n",
    "        self.rewards = rewards  # Reward for each resource\n",
    "        self.usage_duration_distributions = usage_duration_distributions  # Usage duration distributions\n",
    "\n",
    "    def greedy_algorithm(self):\n",
    "        total_reward = 0\n",
    "        resource_availability = [0] * self.N  # Track when resources become available\n",
    "        for t in range(self.T):\n",
    "            available_resources = [i for i in range(self.N) if t >= resource_availability[i]]\n",
    "            # Find the highest reward resource that can be matched\n",
    "            best_resource = None\n",
    "            best_reward = 0\n",
    "            for i in available_resources:\n",
    "                if (i, t) in self.E and self.rewards[i] > best_reward:\n",
    "                    best_reward = self.rewards[i]\n",
    "                    best_resource = i\n",
    "            if best_resource is not None:\n",
    "                total_reward += best_reward\n",
    "                # Sample the usage duration\n",
    "                duration = np.random.choice(self.usage_duration_distributions[best_resource])\n",
    "                resource_availability[best_resource] = t + duration\n",
    "        return total_reward\n",
    "\n",
    "    def clairvoyant_opt(self, arrival_sequence):\n",
    "        total_reward = 0\n",
    "        resource_availability = [0] * self.N\n",
    "        for t in range(self.T):\n",
    "            current_request = arrival_sequence[t]\n",
    "            # Check all resources that can be matched with the current request\n",
    "            for i in range(self.N):\n",
    "                if (i, current_request) in self.E and resource_availability[i] <= t:\n",
    "                    total_reward += self.rewards[i]\n",
    "                    duration = np.random.choice(self.usage_duration_distributions[i])\n",
    "                    resource_availability[i] = t + duration\n",
    "                    break  # Assuming one match per request\n",
    "        return total_reward\n",
    "\n",
    "\n",
    "# Example usage\n",
    "N = 5  # Number of resources\n",
    "T = 10  # Number of requests\n",
    "E = [(i, j) for i in range(N) for j in range(T) if random.random() > 0.5]  # Randomly generate edges\n",
    "rewards = np.random.randint(1, 10, N)\n",
    "usage_duration_distributions = [np.random.randint(1, 5, 10) for _ in range(N)]\n",
    "\n",
    "model = OnlineMatchingModel(N, T, E, rewards, usage_duration_distributions)\n",
    "greedy_reward = model.greedy_algorithm()\n",
    "arrival_sequence = np.random.permutation(T)  # Random arrival sequence for OPT\n",
    "opt_reward = model.clairvoyant_opt(arrival_sequence)\n",
    "\n",
    "print(f\"Greedy Reward: {greedy_reward}\")\n",
    "print(f\"OPT Reward: {opt_reward}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main differences between Inventory Balancing Algorithm and Rank Based Allocation Algorithm:\n",
    "* Goals:\n",
    "    * IBA: Balance the cost of holding inventory with the risk of being out of stock, optimizing inventory levels by adjusting replenishment points and order volumes.\n",
    "    * RBA: Maximize long-term rewards or utility while considering the reuse of resources. By prioritizing the highest-ranking available units, the algorithm attempts to optimize allocation decisions while keeping resources efficiently recycled.\n",
    "* Scenario:\n",
    "    * IBA: Inventory management and demand matching\n",
    "    * RBA: Address the reusability of resources and dynamically reprioritize resource units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inventory Balancing Algorithm (with unreusable resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 1, 4, 2, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "class OnlineMatchingModel:\n",
    "    def __init__(self, N, T, E, rewards):\n",
    "        self.N = N  # Number of offline vertices (resources)\n",
    "        self.T = T  # Number of online vertices (requests)\n",
    "        self.E = E  # Edges in the bipartite graph\n",
    "        self.rewards = rewards  # Reward for each resource\n",
    "        \n",
    "        self.inventory = {}\n",
    "        for n in range(N):\n",
    "            self.inventory[n] = 1 # Each resource is initially set to available\n",
    "\n",
    "        \n",
    "    def g(self, x):\n",
    "        return np.exp(-x)\n",
    "    # Used to adjust the selected weight or priority of each resource\n",
    "    # When the ratio of the resource's remaining inventory x is high, the value of e^(-x) is smaller, \n",
    "    # which means that the priority of resources being selected is correspondingly higher, \n",
    "    # because we are more inclined to use resources with more remaining inventory\n",
    "    \n",
    "    def allocate_resource(self, t):\n",
    "        scores = {}\n",
    "        for n in self.E[t]:\n",
    "            if self.inventory[n] > 0:  # Allocation is considered only when resources are available\n",
    "                score = (1 - self.g(self.inventory[n])) * self.rewards[n]\n",
    "                scores[n] = score\n",
    "\n",
    "        if scores:\n",
    "            selected_resource = max(scores, key=scores.get)\n",
    "            self.inventory[selected_resource] = 0  # After allocation, the resource is marked as unavailable\n",
    "            return selected_resource\n",
    "        return None  # If no resources are available, return None\n",
    "    \n",
    "# sample\n",
    "N = 5\n",
    "T = 10\n",
    "E = {}\n",
    "for t in range(T):\n",
    "    E[t] = range(N)\n",
    "\n",
    "rewards = np.random.rand(N)\n",
    "\n",
    "model = OnlineMatchingModel(N, T, E, rewards)\n",
    "\n",
    "allocations = []\n",
    "for t in range(T):\n",
    "    allocation = model.allocate_resource(t)\n",
    "    allocations.append(allocation)\n",
    "\n",
    "print(allocations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inventory Balancing Algorithm (reusable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3, 3, 4, 4, 3, 4, 4, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class OnlineMatchingModel:\n",
    "    def __init__(self, N, T, E, rewards, usage_duration_distributions):\n",
    "        self.N = N  # Number of offline vertices (resources)\n",
    "        self.T = T  # Number of online vertices (requests)\n",
    "        self.E = E  # Edges in the bipartite graph\n",
    "        self.rewards = rewards  # Reward for each resource\n",
    "        self.usage_duration_distributions = usage_duration_distributions  # Usage duration distributions\n",
    "\n",
    "        self.inventory = {}\n",
    "        for n in range(N):\n",
    "            self.inventory[n] = 1  # Each resource is initially set to available\n",
    "        \n",
    "        self.return_times = {}\n",
    "        for n in range(N):\n",
    "            self.return_times[n] = []  # Initializes the return time list for each resource\n",
    "    \n",
    "    def g(self, x):\n",
    "        return np.exp(-x)\n",
    "    # Used to adjust the selected weight or priority of each resource\n",
    "    # When the ratio of the resource's remaining inventory x is high, the value of e^(-x) is smaller, \n",
    "    # which means that the priority of resources being selected is correspondingly higher, \n",
    "    # because we are more inclined to use resources with more remaining inventory\n",
    "\n",
    "    \n",
    "    def update_inventory(self, current_time):\n",
    "        for n in range(self.N):\n",
    "            updated_return_times = []\n",
    "            for return_time in self.return_times[n]:\n",
    "                if return_time > current_time:\n",
    "                    updated_return_times.append(return_time)\n",
    "            self.return_times[n] = updated_return_times\n",
    "            \n",
    "            if not updated_return_times:  # If there is no resource waiting to be returned, it is set to available\n",
    "                self.inventory[n] = 1\n",
    "            else:\n",
    "                self.inventory[n] = 0\n",
    "    \n",
    "    def allocate_resource(self, t):\n",
    "        self.update_inventory(t)\n",
    "        \n",
    "        scores = {}\n",
    "        for n in self.E[t]:\n",
    "            score = (1 - self.g(self.inventory[n])) * self.rewards[n]\n",
    "            scores[n] = score\n",
    "        \n",
    "        selected_resource = max(scores, key=scores.get)\n",
    "        \n",
    "        duration = np.random.choice(self.usage_duration_distributions[selected_resource])\n",
    "        self.return_times[selected_resource].append(t + duration)\n",
    "        \n",
    "        self.inventory[selected_resource] = 0\n",
    "        \n",
    "        return selected_resource\n",
    "\n",
    "# sample\n",
    "N = 5\n",
    "T = 10\n",
    "E = {}\n",
    "for t in range(T):\n",
    "    E[t] = range(N)\n",
    "\n",
    "rewards = np.random.rand(N)\n",
    "\n",
    "usage_duration_distributions = {}\n",
    "for n in range(N):\n",
    "    usage_duration_distributions[n] = [1, 2, 3]\n",
    "\n",
    "model = OnlineMatchingModel(N, T, E, rewards, usage_duration_distributions)\n",
    "\n",
    "allocations = []\n",
    "for t in range(T):\n",
    "    allocation = model.allocate_resource(t)\n",
    "    allocations.append(allocation)\n",
    "\n",
    "print(allocations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank Based Allocation Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage Duration Distributions: {0: [5, 4], 1: [4, 5], 2: [3, 4], 3: [5, 3]}\n",
      "At time 0, resource 1 unit 1 is allocated\n",
      "At time 1, resource 3 unit 1 is allocated\n",
      "At time 2, resource 2 unit 1 is allocated\n",
      "At time 3, resource 0 unit 1 is allocated\n",
      "At time 4, resource 0 unit 0 is allocated\n",
      "At time 5, resource 1 unit 1 is allocated\n",
      "At time 6, resource 3 unit 1 is allocated\n",
      "At time 7, resource 2 unit 1 is allocated\n",
      "At time 8, resource 0 unit 1 is allocated\n",
      "At time 9, resource 1 unit 1 is allocated\n",
      "At time 10, resource 3 unit 1 is allocated\n",
      "At time 11, resource 2 unit 1 is allocated\n",
      "At time 12, resource 0 unit 0 is allocated\n",
      "At time 13, resource 1 unit 1 is allocated\n",
      "At time 14, resource 3 unit 1 is allocated\n",
      "At time 15, resource 2 unit 1 is allocated\n",
      "At time 16, resource 0 unit 1 is allocated\n",
      "At time 17, resource 3 unit 1 is allocated\n",
      "At time 18, resource 1 unit 1 is allocated\n",
      "At time 19, resource 2 unit 1 is allocated\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class OnlineMatchingModel:\n",
    "    def __init__(self, N, T, E, rewards, usage_duration_distributions):\n",
    "        self.N = N  # Number of resources\n",
    "        self.T = T  # Number of time steps or requests\n",
    "        self.E = E  # Edges representing possible matches between resources and requests\n",
    "        self.rewards = rewards  # Rewards for allocating each resource\n",
    "        self.usage_duration_distributions = usage_duration_distributions  # Usage durations for each resource\n",
    "        \n",
    "        # Initialize resource units' availability, rank, and return time\n",
    "        # self.unit_availability = {n: [True for _ in range(len(usage_duration_distributions[n]))] for n in range(N)}\n",
    "        # self.unit_rank = {n: list(range(len(usage_duration_distributions[n]))) for n in range(N)}\n",
    "        # self.unit_return_time = {n: [-1 for _ in range(len(usage_duration_distributions[n]))] for n in range(N)}\n",
    "        \n",
    "        # Initialize resource units' availability\n",
    "        # For each resource, create a list indicating whether each unit is available\n",
    "        self.unit_availability = {}\n",
    "        for n in range(self.N):  # Iterate over each resource\n",
    "            availability_list = []  # Initialize an empty list for storing availability status of each unit\n",
    "            for _ in range(len(self.usage_duration_distributions[n])):  # Iterate over the number of units for each resource\n",
    "                availability_list.append(True)  # Initially every unit is available\n",
    "            self.unit_availability[n] = availability_list  # Assign the list to the corresponding resource in the dictionary\n",
    "        \n",
    "        # Initialize resource units' rank\n",
    "        # For each resource, create a list indicating the rank of each unit\n",
    "        self.unit_rank = {}\n",
    "        for n in range(self.N):  # Iterate over each resource\n",
    "            rank_list = []  # Initialize an empty list for storing rank of each unit\n",
    "            for rank in range(len(self.usage_duration_distributions[n])):  # Iterate over the number of units for each resource\n",
    "                rank_list.append(rank)  # Assign a rank to each unit\n",
    "            self.unit_rank[n] = rank_list  # Assign the list to the corresponding resource in the dictionary\n",
    "        \n",
    "        # Initialize resource units' return time\n",
    "        # For each resource, create a list indicating the return time of each unit\n",
    "        self.unit_return_time = {}\n",
    "        for n in range(self.N):  # Iterate over each resource\n",
    "            return_time_list = []  # Initialize an empty list for storing return time of each unit\n",
    "            for _ in range(len(self.usage_duration_distributions[n])):  # Iterate over the number of units for each resource\n",
    "                return_time_list.append(-1)  # Initially, there is no return time (-1 indicates not in use)\n",
    "            self.unit_return_time[n] = return_time_list  # Assign the list to the corresponding resource in the dictionary\n",
    "\n",
    "\n",
    "    def g(self, x):\n",
    "        return np.exp(-x)\n",
    "    \n",
    "    def update_availability(self, t):\n",
    "        # Iterate over each resource to update its units' availability\n",
    "        for i in range(self.N):\n",
    "            # Iterate over each unit of the resource\n",
    "            for k in range(len(self.unit_availability[i])):\n",
    "                # Check if the current time is greater than or equal to the return time of the unit\n",
    "                if t >= self.unit_return_time[i][k]:\n",
    "                    # If so, make the unit available again\n",
    "                    self.unit_availability[i][k] = True\n",
    "\n",
    "    def allocate_resource(self, t):\n",
    "        # First, update the availability of all resources at time t\n",
    "        self.update_availability(t)\n",
    "        \n",
    "        # Initialize a dictionary to store the scores for each available resource\n",
    "        scores = {}\n",
    "        # Iterate over the resources that are available at time t\n",
    "        for i in self.E[t]:\n",
    "            # Find all available units of resource i\n",
    "            available_units = [k for k, available in enumerate(self.unit_availability[i]) if available]\n",
    "            # If there are available units, calculate the score for the resource\n",
    "            if available_units:\n",
    "                # Find the highest ranked available unit of resource i\n",
    "                highest_ranked_unit = max(available_units, key=lambda x: self.unit_rank[i][x])\n",
    "                # Calculate the score based on the reward and the rank of the unit\n",
    "                scores[i] = self.rewards[i] * (1 - self.g(self.unit_rank[i][highest_ranked_unit] / len(self.unit_rank[i])))\n",
    "\n",
    "        # If there are any scores calculated, proceed to allocate a resource\n",
    "        if scores:\n",
    "            # Select the resource with the highest score\n",
    "            selected_resource = max(scores, key=scores.get)\n",
    "            # Find the highest ranked available unit of the selected resource\n",
    "            selected_unit = max([k for k, available in enumerate(self.unit_availability[selected_resource]) if available], \n",
    "                                key=lambda x: self.unit_rank[selected_resource][x])\n",
    "            # Mark the selected unit as unavailable\n",
    "            self.unit_availability[selected_resource][selected_unit] = False\n",
    "            # Set the return time for the unit based on the selected usage duration\n",
    "            duration = np.random.choice(self.usage_duration_distributions[selected_resource])\n",
    "            self.unit_return_time[selected_resource][selected_unit] = t + duration\n",
    "            # Return the selected resource and unit\n",
    "            return selected_resource, selected_unit\n",
    "        else:\n",
    "            # If no resources are available, return None\n",
    "            return None, None\n",
    "\n",
    "\n",
    "# Example usage\n",
    "N = 4  # Number of resources\n",
    "T = 20  # Number of time steps or requests\n",
    "E = {t: range(N) for t in range(T)}  # Possible matches between resources and requests  ### random edges\n",
    "rewards = np.random.rand(N)  # Random rewards for each resource\n",
    "\n",
    "# Generate usage duration distributions randomly\n",
    "usage_duration_distributions = {}\n",
    "for n in range(N):\n",
    "    usage_duration_distributions[n] = np.random.choice(range(3, 6), size=2, replace=False).tolist()\n",
    "\n",
    "print(\"Usage Duration Distributions:\", usage_duration_distributions)\n",
    "\n",
    "model = OnlineMatchingModel(N, T, E, rewards, usage_duration_distributions)\n",
    "\n",
    "for t in range(T):\n",
    "    resource, unit = model.allocate_resource(t)\n",
    "    if resource is not None:\n",
    "        print(f\"At time {t}, resource {resource} unit {unit} is allocated\")\n",
    "    else:\n",
    "        print(f\"At time {t}, no resource is allocated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic Assortment Optimization for Reusable Products with Random Usage Durations\n",
    "\n",
    "It is assumed that the expected revenue of each product depends not only on its own attributes but also on time. To simplify, we assume that the expected return on each product decreases linearly over time, meaning that each product may become less attractive over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the Online Matching Model...\n",
      "\n",
      "Time Step 0: X---\n",
      "Time Step 1: X--X\n",
      "Time Step 2: X-XX\n",
      "Time Step 3: ---X\n",
      "Time Step 4: --XX\n",
      "Time Step 5: -X--\n",
      "Time Step 6: XX--\n",
      "Time Step 7: XXX-\n",
      "Time Step 8: XXX-\n",
      "Time Step 9: -XX-\n",
      "Time Step 10: -XX-\n",
      "Time Step 11: -X--\n",
      "Time Step 12: XX--\n",
      "Time Step 13: XXX-\n",
      "Time Step 14: XX-X\n",
      "Time Step 15: X--X\n",
      "Time Step 16: X-X-\n",
      "Time Step 17: --X-\n",
      "Time Step 18: -XX-\n",
      "Time Step 19: -XX-\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class OnlineMatchingModel:\n",
    "    def __init__(self, N, T, rewards, usage_duration_distributions):\n",
    "        self.N = N  # Number of resources\n",
    "        self.T = T  # Number of time steps or requests\n",
    "        self.rewards = rewards  # Matrix of rewards\n",
    "        self.usage_duration_distributions = usage_duration_distributions  # Distribution of usage durations\n",
    "        self.state = np.zeros((N, T))  # State of each resource over time\n",
    "        self.linear_approximations = np.zeros((N, T))  # Linear approximation values\n",
    "\n",
    "    def compute_linear_approximations(self):\n",
    "        for t in range(self.T):\n",
    "            for n in range(self.N):\n",
    "                previous_resource_state = self.state[(n - 1) % self.N, t]\n",
    "                if previous_resource_state == 1:\n",
    "                    dependency_factor = 0.9\n",
    "                else:\n",
    "                    dependency_factor = 1.1\n",
    "                \n",
    "                adjusted_reward = self.rewards[n, t] * dependency_factor\n",
    "                time_decay = t * 0.1\n",
    "                self.linear_approximations[n, t] = adjusted_reward - time_decay\n",
    "\n",
    "    def transition_function(self, allocations, t):\n",
    "        for n in allocations:\n",
    "            duration = np.random.choice(self.usage_duration_distributions[n], 1)[0]\n",
    "            end_time = min(t + duration, self.T)\n",
    "            self.state[n, t:end_time] = 1\n",
    "\n",
    "    def greedy_policy(self, t):\n",
    "        available_resources = []\n",
    "        for n in range(self.N):\n",
    "            if self.state[n, t] == 0:\n",
    "                available_resources.append(n)\n",
    "\n",
    "        if not available_resources:\n",
    "            return []\n",
    "\n",
    "        # Find the resource with the maximum linear approximation value\n",
    "        max_value = float('-inf')\n",
    "        max_resource = None\n",
    "        for resource in available_resources:\n",
    "            if self.linear_approximations[resource, t] > max_value:\n",
    "                max_value = self.linear_approximations[resource, t]\n",
    "                max_resource = resource\n",
    "\n",
    "        return [max_resource] if max_resource is not None else []\n",
    "\n",
    "    def run(self):\n",
    "        self.compute_linear_approximations()\n",
    "        print(\"Running the Online Matching Model...\\n\")\n",
    "        for t in range(self.T):\n",
    "            allocations = self.greedy_policy(t)\n",
    "            self.transition_function(allocations, t)\n",
    "\n",
    "            # Generate the resource state string\n",
    "            resource_states = ''\n",
    "            for n in range(self.N):\n",
    "                resource_states += 'X' if self.state[n, t] else '-'\n",
    "            print(f\"Time Step {t}: {resource_states}\")\n",
    "\n",
    "# Example usage\n",
    "N = 4  # Number of resources\n",
    "T = 20  # Number of time steps\n",
    "rewards = np.random.rand(N, T)  # Random rewards\n",
    "usage_duration_distributions = [[1, 2, 3], [2, 3, 4], [1, 2], [2]]  # Modified usage durations\n",
    "\n",
    "model = OnlineMatchingModel(N, T, rewards, usage_duration_distributions)\n",
    "model.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/yiling/miniconda3/lib/python3.10/site-packages/pulp/solverdir/cbc/osx/64/cbc /var/folders/_t/29cl1rrn5zvbhm_4ys4wb81h0000gn/T/c433c131d08b463998f1d4535c9d7dac-pulp.mps -max -timeMode elapsed -branch -printingOptions all -solution /var/folders/_t/29cl1rrn5zvbhm_4ys4wb81h0000gn/T/c433c131d08b463998f1d4535c9d7dac-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 310 COLUMNS\n",
      "At line 4811 RHS\n",
      "At line 5117 BOUNDS\n",
      "At line 6618 ENDATA\n",
      "Problem MODEL has 305 rows, 1500 columns and 3000 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Presolve 305 (0) rows, 1500 (0) columns and 3000 (0) elements\n",
      "Perturbing problem by 0.001% of 1732.3259 - largest nonzero change 0.00017413699 ( 0.35806386%) - largest zero change 0\n",
      "0  Obj -0 Dual inf 6398551 (1500)\n",
      "81  Obj 27662.525 Primal inf 2863.0809 (244)\n",
      "144  Obj 24529.514 Primal inf 955.55122 (203)\n",
      "212  Obj 19588.402 Primal inf 85.867114 (137)\n",
      "293  Obj 12906.216 Primal inf 5.9240752 (56)\n",
      "349  Obj 8286.219\n",
      "Optimal - objective value 8286.4707\n",
      "Optimal objective 8286.470743 - 349 iterations time 0.002\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.01   (Wallclock seconds):       0.02\n",
      "\n",
      "Inventory level 1: Expected Max Revenue = $8286.47\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/yiling/miniconda3/lib/python3.10/site-packages/pulp/solverdir/cbc/osx/64/cbc /var/folders/_t/29cl1rrn5zvbhm_4ys4wb81h0000gn/T/7e46eab0eab14f4487f85b256a0a08b0-pulp.mps -max -timeMode elapsed -branch -printingOptions all -solution /var/folders/_t/29cl1rrn5zvbhm_4ys4wb81h0000gn/T/7e46eab0eab14f4487f85b256a0a08b0-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 310 COLUMNS\n",
      "At line 4811 RHS\n",
      "At line 5117 BOUNDS\n",
      "At line 6618 ENDATA\n",
      "Problem MODEL has 305 rows, 1500 columns and 3000 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Presolve 305 (0) rows, 1500 (0) columns and 3000 (0) elements\n",
      "Perturbing problem by 0.001% of 1732.3259 - largest nonzero change 0.00017413699 ( 0.35806386%) - largest zero change 0\n",
      "0  Obj -0 Dual inf 6398551 (1500)\n",
      "74  Obj 30327.966 Primal inf 9537.7935 (272)\n",
      "147  Obj 26239.252 Primal inf 1039.4367 (214)\n",
      "228  Obj 19722.284 Primal inf 85.588415 (132)\n",
      "309  Obj 13122.271 Primal inf 4.8958303 (51)\n",
      "360  Obj 8914.7708\n",
      "Optimal - objective value 8915.7994\n",
      "Optimal objective 8915.799398 - 360 iterations time 0.002\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.01   (Wallclock seconds):       0.01\n",
      "\n",
      "Inventory level 5: Expected Max Revenue = $8915.80\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/yiling/miniconda3/lib/python3.10/site-packages/pulp/solverdir/cbc/osx/64/cbc /var/folders/_t/29cl1rrn5zvbhm_4ys4wb81h0000gn/T/736beedc2f674318b775eda51593c18f-pulp.mps -max -timeMode elapsed -branch -printingOptions all -solution /var/folders/_t/29cl1rrn5zvbhm_4ys4wb81h0000gn/T/736beedc2f674318b775eda51593c18f-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 310 COLUMNS\n",
      "At line 4811 RHS\n",
      "At line 5117 BOUNDS\n",
      "At line 6618 ENDATA\n",
      "Problem MODEL has 305 rows, 1500 columns and 3000 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Presolve 0 (-305) rows, 0 (-1500) columns and 0 (-3000) elements\n",
      "Empty problem - 0 rows, 0 columns and 0 elements\n",
      "Optimal - objective value 9000\n",
      "After Postsolve, objective 9000, infeasibilities - dual 24750 (1200), primal 0 (0)\n",
      "Presolved model was optimal, full model needs cleaning up\n",
      "0  Obj 9000 Dual inf 4693141.4 (1200)\n",
      "200  Obj 9000 Dual inf 1282.2891 (411)\n",
      "400  Obj 9000 Dual inf 0.98466554 (54)\n",
      "443  Obj 9000\n",
      "Optimal - objective value 9000\n",
      "Optimal objective 9000.000001 - 443 iterations time 0.002, Presolve 0.00\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.01   (Wallclock seconds):       0.01\n",
      "\n",
      "Inventory level 20: Expected Max Revenue = $9000.00\n"
     ]
    }
   ],
   "source": [
    "import pulp as pl\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "n = 5  # Number of products\n",
    "T = 300  # Number of periods\n",
    "prices = np.linspace(15, 30, n)  # Prices of products\n",
    "inventory_levels = [1, 5, 20]  # Inventory levels\n",
    "probabilities = np.array([1 / (20 - i) for i in range(1, 6)])  # Geometric distribution parameters\n",
    "\n",
    "# Prepare survival probabilities for the geometric distribution\n",
    "survival_probabilities = np.array([(1 - probabilities[i]) ** np.arange(T) for i in range(n)])\n",
    "\n",
    "# Each inventory level simulation\n",
    "results = {}\n",
    "for inventory_level in inventory_levels:\n",
    "    # Define the problem\n",
    "    model = pl.LpProblem(\"Maximize_Revenue\", pl.LpMaximize)\n",
    "\n",
    "    # Decision variables: X[t, i] is continuous between 0 and 1\n",
    "    X = pl.LpVariable.dicts(\"X\", (range(T), range(n)), lowBound=0, upBound=1, cat=pl.LpContinuous)\n",
    "\n",
    "    # Objective function: Maximize expected total revenue\n",
    "    objective = pl.lpSum([X[t][i] * prices[i] for t in range(T) for i in range(n)])\n",
    "    model += objective\n",
    "\n",
    "    # Constraints\n",
    "    # Constraint 1: The sum of probabilities for matching items in each time period cannot exceed 1\n",
    "    for t in range(T):\n",
    "        model += pl.lpSum([X[t][i] for i in range(n)]) <= 1, f\"Max_One_Product_Per_Period_{t}\"\n",
    "\n",
    "    # Constraint 2: Cumulative expected matching for each item should not exceed its maximum capacity\n",
    "    for i in range(n):\n",
    "        model += pl.lpSum([X[t][i] * survival_probabilities[i][t] for t in range(T)]) <= inventory_level, f\"Inventory_Limits_{i}\"\n",
    "\n",
    "    # Constraint 4: Matching only if there is an edge (assuming always available for simplicity)\n",
    "    # If specific conditions where an item is not available are needed, adjust this constraint accordingly\n",
    "\n",
    "    # Solve the problem\n",
    "    model.solve()\n",
    "\n",
    "    # Output results\n",
    "    total_revenue = pl.value(model.objective)\n",
    "    results[inventory_level] = total_revenue\n",
    "    print(f\"Inventory level {inventory_level}: Expected Max Revenue = ${total_revenue:.2f}\")\n",
    "\n",
    "# Optional: Print decision variable values (e.g., print(X[t][i].varValue) for specific t, i)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
