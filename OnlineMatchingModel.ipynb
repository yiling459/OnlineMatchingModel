{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy Reward: 49\n",
      "OPT Reward: 49\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class OnlineMatchingModel:\n",
    "    def __init__(self, N, T, E, rewards, usage_duration_distributions):\n",
    "        # Initialize the model parameters\n",
    "        self.N = N  # Number of offline vertices (resources)\n",
    "        self.T = T  # Number of online vertices (requests)\n",
    "        self.E = E  # Edges in the bipartite graph\n",
    "        self.rewards = rewards  # Reward for each resource\n",
    "        self.usage_duration_distributions = usage_duration_distributions  # Usage duration distributions\n",
    "\n",
    "    def greedy_algorithm(self):\n",
    "        total_reward = 0\n",
    "        resource_availability = [0] * self.N  # Track when resources become available\n",
    "        for t in range(self.T):\n",
    "            available_resources = [i for i in range(self.N) if t >= resource_availability[i]]\n",
    "            # Find the highest reward resource that can be matched\n",
    "            best_resource = None\n",
    "            best_reward = 0\n",
    "            for i in available_resources:\n",
    "                if (i, t) in self.E and self.rewards[i] > best_reward:\n",
    "                    best_reward = self.rewards[i]\n",
    "                    best_resource = i\n",
    "            if best_resource is not None:\n",
    "                total_reward += best_reward\n",
    "                # Sample the usage duration\n",
    "                duration = np.random.choice(self.usage_duration_distributions[best_resource])\n",
    "                resource_availability[best_resource] = t + duration\n",
    "        return total_reward\n",
    "\n",
    "    def clairvoyant_opt(self, arrival_sequence):\n",
    "        total_reward = 0\n",
    "        resource_availability = [0] * self.N\n",
    "        for t in range(self.T):\n",
    "            current_request = arrival_sequence[t]\n",
    "            # Check all resources that can be matched with the current request\n",
    "            for i in range(self.N):\n",
    "                if (i, current_request) in self.E and resource_availability[i] <= t:\n",
    "                    total_reward += self.rewards[i]\n",
    "                    duration = np.random.choice(self.usage_duration_distributions[i])\n",
    "                    resource_availability[i] = t + duration\n",
    "                    break  # Assuming one match per request\n",
    "        return total_reward\n",
    "\n",
    "\n",
    "# Example usage\n",
    "N = 5  # Number of resources\n",
    "T = 10  # Number of requests\n",
    "E = [(i, j) for i in range(N) for j in range(T) if random.random() > 0.5]  # Randomly generate edges\n",
    "rewards = np.random.randint(1, 10, N)\n",
    "usage_duration_distributions = [np.random.randint(1, 5, 10) for _ in range(N)]\n",
    "\n",
    "model = OnlineMatchingModel(N, T, E, rewards, usage_duration_distributions)\n",
    "greedy_reward = model.greedy_algorithm()\n",
    "arrival_sequence = np.random.permutation(T)  # Random arrival sequence for OPT\n",
    "opt_reward = model.clairvoyant_opt(arrival_sequence)\n",
    "\n",
    "print(f\"Greedy Reward: {greedy_reward}\")\n",
    "print(f\"OPT Reward: {opt_reward}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inventory Balancing Algorithm (with unreusable resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 1, 4, 2, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "class OnlineMatchingModel:\n",
    "    def __init__(self, N, T, E, rewards):\n",
    "        self.N = N  # Number of offline vertices (resources)\n",
    "        self.T = T  # Number of online vertices (requests)\n",
    "        self.E = E  # Edges in the bipartite graph\n",
    "        self.rewards = rewards  # Reward for each resource\n",
    "        \n",
    "        self.inventory = {}\n",
    "        for n in range(N):\n",
    "            self.inventory[n] = 1 # Each resource is initially set to available\n",
    "\n",
    "        \n",
    "    def g(self, x):\n",
    "        return np.exp(-x)\n",
    "    # Used to adjust the selected weight or priority of each resource\n",
    "    # When the ratio of the resource's remaining inventory x is high, the value of e^(-x) is smaller, \n",
    "    # which means that the priority of resources being selected is correspondingly higher, \n",
    "    # because we are more inclined to use resources with more remaining inventory\n",
    "    \n",
    "    def allocate_resource(self, t):\n",
    "        scores = {}\n",
    "        for n in self.E[t]:\n",
    "            if self.inventory[n] > 0:  # Allocation is considered only when resources are available\n",
    "                score = (1 - self.g(self.inventory[n])) * self.rewards[n]\n",
    "                scores[n] = score\n",
    "\n",
    "        if scores:\n",
    "            selected_resource = max(scores, key=scores.get)\n",
    "            self.inventory[selected_resource] = 0  # After allocation, the resource is marked as unavailable\n",
    "            return selected_resource\n",
    "        return None  # If no resources are available, return None\n",
    "    \n",
    "# sample\n",
    "N = 5\n",
    "T = 10\n",
    "E = {}\n",
    "for t in range(T):\n",
    "    E[t] = range(N)\n",
    "\n",
    "rewards = np.random.rand(N)\n",
    "\n",
    "model = OnlineMatchingModel(N, T, E, rewards)\n",
    "\n",
    "allocations = []\n",
    "for t in range(T):\n",
    "    allocation = model.allocate_resource(t)\n",
    "    allocations.append(allocation)\n",
    "\n",
    "print(allocations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inventory Balancing Algorithm (reusable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3, 3, 4, 4, 3, 4, 4, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class OnlineMatchingModel:\n",
    "    def __init__(self, N, T, E, rewards, usage_duration_distributions):\n",
    "        self.N = N  # Number of offline vertices (resources)\n",
    "        self.T = T  # Number of online vertices (requests)\n",
    "        self.E = E  # Edges in the bipartite graph\n",
    "        self.rewards = rewards  # Reward for each resource\n",
    "        self.usage_duration_distributions = usage_duration_distributions  # Usage duration distributions\n",
    "\n",
    "        self.inventory = {}\n",
    "        for n in range(N):\n",
    "            self.inventory[n] = 1  # Each resource is initially set to available\n",
    "        \n",
    "        self.return_times = {}\n",
    "        for n in range(N):\n",
    "            self.return_times[n] = []  # Initializes the return time list for each resource\n",
    "    \n",
    "    def g(self, x):\n",
    "        return np.exp(-x)\n",
    "    # Used to adjust the selected weight or priority of each resource\n",
    "    # When the ratio of the resource's remaining inventory x is high, the value of e^(-x) is smaller, \n",
    "    # which means that the priority of resources being selected is correspondingly higher, \n",
    "    # because we are more inclined to use resources with more remaining inventory\n",
    "\n",
    "    \n",
    "    def update_inventory(self, current_time):\n",
    "        for n in range(self.N):\n",
    "            updated_return_times = []\n",
    "            for return_time in self.return_times[n]:\n",
    "                if return_time > current_time:\n",
    "                    updated_return_times.append(return_time)\n",
    "            self.return_times[n] = updated_return_times\n",
    "            \n",
    "            if not updated_return_times:  # If there is no resource waiting to be returned, it is set to available\n",
    "                self.inventory[n] = 1\n",
    "            else:\n",
    "                self.inventory[n] = 0\n",
    "    \n",
    "    def allocate_resource(self, t):\n",
    "        self.update_inventory(t)\n",
    "        \n",
    "        scores = {}\n",
    "        for n in self.E[t]:\n",
    "            score = (1 - self.g(self.inventory[n])) * self.rewards[n]\n",
    "            scores[n] = score\n",
    "        \n",
    "        selected_resource = max(scores, key=scores.get)\n",
    "        \n",
    "        duration = np.random.choice(self.usage_duration_distributions[selected_resource])\n",
    "        self.return_times[selected_resource].append(t + duration)\n",
    "        \n",
    "        self.inventory[selected_resource] = 0\n",
    "        \n",
    "        return selected_resource\n",
    "\n",
    "# sample\n",
    "N = 5\n",
    "T = 10\n",
    "E = {}\n",
    "for t in range(T):\n",
    "    E[t] = range(N)\n",
    "\n",
    "rewards = np.random.rand(N)\n",
    "\n",
    "usage_duration_distributions = {}\n",
    "for n in range(N):\n",
    "    usage_duration_distributions[n] = [1, 2, 3]\n",
    "\n",
    "model = OnlineMatchingModel(N, T, E, rewards, usage_duration_distributions)\n",
    "\n",
    "allocations = []\n",
    "for t in range(T):\n",
    "    allocation = model.allocate_resource(t)\n",
    "    allocations.append(allocation)\n",
    "\n",
    "print(allocations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank Based Allocation Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 0: Resource 1 allocated for 3 time units\n",
      "Time 1: Resource 2 allocated for 3 time units\n",
      "Time 2: Resource 1 allocated for 3 time units\n",
      "Time 3: Resource 2 allocated for 3 time units\n",
      "Time 4: Resource 0 allocated for 1 time units\n",
      "Time 5: Resource 1 allocated for 3 time units\n",
      "Time 6: Resource 4 allocated for 3 time units\n",
      "Time 7: Resource 2 allocated for 3 time units\n",
      "Time 8: Resource 3 allocated for 1 time units\n",
      "Time 9: Resource 4 allocated for 3 time units\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class OnlineMatchingModel:\n",
    "    def __init__(self, N, T, E, rewards, usage_duration_distributions):\n",
    "        self.N = N  # Number of offline vertices (resources)\n",
    "        self.T = T  # Number of online vertices (requests)\n",
    "        self.E = E  # Edges in the bipartite graph\n",
    "        self.rewards = rewards  # Reward for each resource\n",
    "        self.usage_duration_distributions = usage_duration_distributions  # Usage duration distributions\n",
    "        \n",
    "        # Initialize the availability and ranking of each unit of the resources\n",
    "        self.availability = {n: [True] * self.usage_duration_distributions[n][0] for n in range(self.N)}\n",
    "        # The ranking is simplified as a list of boolean values indicating availability\n",
    "\n",
    "    def g(self, x):\n",
    "        # Decreasing function g(x) = e^(-x)\n",
    "        return np.exp(-x)\n",
    "    \n",
    "    def allocate_resource(self, t):\n",
    "        scores = {}\n",
    "        for i in self.E[t]:\n",
    "            if any(self.availability[i]):  # Check if there's any unit available for resource i\n",
    "                highest_available_unit = max([k for k, available in enumerate(self.availability[i]) if available])\n",
    "                scores[i] = self.rewards[i] * (1 - self.g((highest_available_unit + 1) / len(self.availability[i])))\n",
    "\n",
    "        if scores:\n",
    "            selected_resource = max(scores, key=scores.get)\n",
    "            # Mark the highest ranked available unit of the selected resource as unavailable\n",
    "            highest_available_unit = max([k for k, available in enumerate(self.availability[selected_resource]) if available])\n",
    "            self.availability[selected_resource][highest_available_unit] = False\n",
    "            # Set a timer for when the unit will become available again, based on the usage duration distribution\n",
    "            return selected_resource, self.usage_duration_distributions[selected_resource][0]  # Simplified: always use the first duration\n",
    "        else:\n",
    "            return None, None  # No resource is available\n",
    "\n",
    "# Sample usage\n",
    "N = 5\n",
    "T = 10\n",
    "E = {t: range(N) for t in range(T)}\n",
    "rewards = np.random.rand(N)\n",
    "usage_duration_distributions = {n: [np.random.choice([1, 2, 3])] for n in range(N)}\n",
    "\n",
    "model = OnlineMatchingModel(N, T, E, rewards, usage_duration_distributions)\n",
    "\n",
    "for t in range(T):\n",
    "    resource, duration = model.allocate_resource(t)\n",
    "    if resource is not None:\n",
    "        print(f\"Time {t}: Resource {resource} allocated for {duration} time units\")\n",
    "    else:\n",
    "        print(f\"Time {t}: No resource allocated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
